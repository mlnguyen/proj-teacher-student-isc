{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "\n",
    "from os.path import isfile, join, exists\n",
    "from os import listdir, makedirs, walk, remove, getlogin\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "from nilearn import image, masking\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp params\n",
    "projdir = '/mnt/bucket/labs/hasson/mai/projects/b2b_teaching'\n",
    "    \n",
    "run_list = ['teach1_epi_lesson1', 'teach2_epi_lesson2', 'teach2_epi_lesson3', \n",
    "            'teach3_epi_lesson4', 'teach3_epi_lesson5']\n",
    "\n",
    "hrf = 3\n",
    "model_epi = 'teach2_epi_lesson3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get time stamps\n",
    "x1 = pd.ExcelFile(join(projdir, 'recordings', 'lesson_timestamps.xlsx'))\n",
    "df_times = x1.parse('times')\n",
    "\n",
    "df_times = df_times.drop([0])\n",
    "timestamps = {};\n",
    "for i,run in enumerate(run_list):\n",
    "    trs = df_times['tr' + str(i+1)]\n",
    "    timestamps[run] = trs.tolist()\n",
    "\n",
    "for run in run_list:\n",
    "    times = timestamps[run]\n",
    "    for i in range(len(times)-1):\n",
    "        this_time = times[i]\n",
    "        next_time = times[i+1]\n",
    "        if next_time <= this_time:\n",
    "            print('out of order: run ' + run + ', ind ' + str(i) + ', tr ' + str(times[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get times for model epi\n",
    "event_len = []\n",
    "model_times = timestamps[model_epi]\n",
    "\n",
    "for i in range(len(model_times)-1):\n",
    "    time_len = model_times[i+1] - model_times[i]\n",
    "    event_len.append(int(time_len))\n",
    "\n",
    "# get last event time\n",
    "datafile = join(projdir, 'teach_data', 'data', model_epi + '_data.pk1')\n",
    "pkl_file = open(datafile, 'rb')\n",
    "datadict = pickle.load(pkl_file)\n",
    "pkl_file.close()\n",
    "subdata = datadict['data']\n",
    "\n",
    "# last time\n",
    "last_len = subdata.shape[1] - model_times[-1]\n",
    "event_len.append(int(last_len))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teach1_epi_lesson1...\n",
      "teach2_epi_lesson2...\n",
      "teach2_epi_lesson3...\n",
      "teach3_epi_lesson4...\n",
      "teach3_epi_lesson5...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#run = run_list[0]\n",
    "\n",
    "for run in run_list:\n",
    "    print(run + '...')\n",
    "    # load data\n",
    "    datafile = join(projdir, 'teach_data', 'data', run + '_data.pk1')\n",
    "    pkl_file = open(datafile, 'rb')\n",
    "    datadict = pickle.load(pkl_file)\n",
    "    pkl_file.close()\n",
    "    subdata = datadict['data']\n",
    "\n",
    "    # mask data so only non-nan voxels\n",
    "    goodvox_mask = ~np.isnan(np.mean(subdata,axis=1))\n",
    "    subdata_good = subdata[goodvox_mask,:]\n",
    "\n",
    "    # event times for this run\n",
    "    times = timestamps[run]\n",
    "\n",
    "    # get event data and stretch\n",
    "    for i in range(len(times)):\n",
    "\n",
    "        # get event data\n",
    "        start = int(times[i]) + hrf\n",
    "        if i == len(times)-1:\n",
    "            stop = subdata_good.shape[1]\n",
    "        else:\n",
    "            stop = int(times[i+1]) + hrf\n",
    "        ev_orig = subdata_good[:, start:stop]\n",
    "\n",
    "        # stretch\n",
    "        ev_stretch = librosa.core.resample(ev_orig, ev_orig.shape[1], event_len[i])\n",
    "\n",
    "        # build up timeseries\n",
    "        if i == 0:\n",
    "            sub_stretch = ev_stretch\n",
    "        else:\n",
    "            sub_stretch = np.concatenate([sub_stretch, ev_stretch], axis=1)\n",
    "\n",
    "    # unmask-put back in original order\n",
    "    subdata_stretch = np.full([subdata.shape[0], sub_stretch.shape[1]], np.nan)\n",
    "    subdata_stretch[goodvox_mask,:] = sub_stretch\n",
    "    \n",
    "    # save\n",
    "    datadict['data'] = subdata_stretch\n",
    "    datadict['stretch'] = 1\n",
    "    datadict['modelEPI'] = model_epi\n",
    "    datadict['origDatafile'] = datafile\n",
    "    datadict['hrf'] = hrf\n",
    "    \n",
    "    savename = join(projdir, 'teach_data', 'data', run + '_data_hrf' + str(hrf) + '_stretch.pk1')\n",
    "    output = open(savename, 'wb')\n",
    "    pickle.dump(datadict, output)\n",
    "    output.close()\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data_list = []\n",
    "for run in run_list:\n",
    "    datafile = join(projdir, 'teach_data', 'data', run + '_data_hrf' + str(hrf) + '_stretch.pk1')\n",
    "    pkl_file = open(datafile, 'rb')\n",
    "    datadict = pickle.load(pkl_file)\n",
    "    pkl_file.close()\n",
    "\n",
    "    # get data\n",
    "    data_list.append(datadict['data'])\n",
    "\n",
    "# convert data to numpy array\n",
    "data = np.asarray(data_list)\n",
    "\n",
    "# get sum of all\n",
    "data_sum = np.nansum(data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teach1_epi_lesson1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jukebox/pkgs/PYGER/beta/lib/python3.6/site-packages/scipy/stats/stats.py:2245: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.expand_dims(sstd, axis=axis))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teach2_epi_lesson2...\n",
      "teach2_epi_lesson3...\n",
      "teach3_epi_lesson4...\n",
      "teach3_epi_lesson5...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# do isc\n",
    "r_all = []\n",
    "for i,subdata in enumerate(data):\n",
    "    print(run_list[i] + '...')\n",
    "    avg_others = (data_sum - subdata) / (data.shape[0]-1)\n",
    "    r = corr_fast(subdata, avg_others)\n",
    "    r_all.append(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_all = np.asarray(r_all)\n",
    "isc = np.nanmean(r_all, axis=0)\n",
    "\n",
    "# convert to nifti\n",
    "mask_nifti = image.load_img(datadict['mask'])\n",
    "data_unmask = masking.unmask(isc, mask_nifti)\n",
    "\n",
    "# save nifti\n",
    "savename = join(projdir, 'teach_data', 'analysis', 'isc_teachData.nii.gz')\n",
    "data_unmask.to_filename(savename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/bucket/labs/hasson/mai/projects/b2b_teaching/teach_data/analysis/isc_teachData.nii.gz'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "savename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_fast(mat1, mat2):\n",
    "# Vectorized method for correlating rows of one matrix with another\n",
    "    \n",
    "    # zscore\n",
    "    mat1_z = stats.zscore(mat1, axis=1, ddof=1)\n",
    "    mat2_z = stats.zscore(mat2, axis=1)\n",
    "            \n",
    "    # Calculate sum of products\n",
    "    sum_vec = np.nansum(np.transpose(mat1_z) * np.transpose(mat2_z),\n",
    "                        axis = 0)\n",
    "                        \n",
    "    # Calculate degrees of free\n",
    "    dof = mat1.shape[1] - 1\n",
    "    \n",
    "    # Correlation coeff\n",
    "    r = sum_vec/dof        \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65323, 1035)\n",
      "(61417, 1035)\n",
      "(61417, 978)\n",
      "(65323, 978)\n"
     ]
    }
   ],
   "source": [
    "print(subdata.shape)\n",
    "print(subdata_good.shape)\n",
    "print(sub_stretch.shape)\n",
    "print(subdata_stretch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/bucket/labs/hasson/mai/standard/MNI_brains/MNI152_T1_3mm_brain_mask_bin.nii'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadict['mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
